version: '3.8'

# Production Stack
# Optimized for production deployment with health checks, resource limits, and security

services:
  # ==========================================
  # APPLICATION
  # ==========================================

  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: zaaz-server-prod
    restart: always
    ports:
      - '${APP_PORT:-5000}:5000'
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - REDIS_ENABLED=true
      - RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@rabbitmq:5672
      - RABBITMQ_ENABLED=${RABBITMQ_ENABLED:-false}
      - KAFKA_BROKERS=kafka:9093
      - KAFKA_ENABLED=${KAFKA_ENABLED:-false}
      - CLUSTER_ENABLED=true
      - PORT=5000
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - prod-network
    volumes:
      - ./logs:/app/logs:rw
      - ./public:/app/public:ro
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--quiet',
          '--tries=1',
          '--spider',
          'http://localhost:5000/health',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # ==========================================
  # CACHE
  # ==========================================

  redis:
    image: redis:7-alpine
    container_name: zaaz-redis-prod
    restart: always
    ports:
      - '127.0.0.1:${REDIS_PORT:-6379}:6379'
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    networks:
      - prod-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ['CMD', 'redis-cli', '-a', '${REDIS_PASSWORD}', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # ==========================================
  # MESSAGE BROKERS (Optional - Enable as needed)
  # ==========================================

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: zaaz-rabbitmq-prod
    restart: always
    ports:
      - '127.0.0.1:${RABBITMQ_PORT:-5672}:5672'
      - '127.0.0.1:${RABBITMQ_MANAGEMENT_PORT:-15672}:15672'
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASS}
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 1GB
      RABBITMQ_DISK_FREE_LIMIT: 5GB
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - prod-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ['CMD', 'rabbitmq-diagnostics', '-q', 'ping']
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    profiles:
      - rabbitmq

  # Zookeeper (for Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zaaz-zookeeper-prod
    restart: always
    ports:
      - '127.0.0.1:${ZOOKEEPER_PORT:-2181}:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    networks:
      - prod-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ['CMD', 'nc', '-z', 'localhost', '2181']
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    profiles:
      - kafka

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: zaaz-kafka-prod
    restart: always
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - '127.0.0.1:${KAFKA_PORT:-9092}:9092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_HEAP_OPTS: '-Xmx1G -Xms512M'
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - prod-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test:
        [
          'CMD',
          'kafka-broker-api-versions',
          '--bootstrap-server',
          'localhost:9092',
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    profiles:
      - kafka

  # ==========================================
  # REVERSE PROXY (Optional - Nginx)
  # ==========================================

  nginx:
    image: nginx:alpine
    container_name: zaaz-nginx-prod
    restart: always
    depends_on:
      app:
        condition: service_healthy
    ports:
      - '${NGINX_HTTP_PORT:-80}:80'
      - '${NGINX_HTTPS_PORT:-443}:443'
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./public:/usr/share/nginx/html:ro
    networks:
      - prod-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--quiet',
          '--tries=1',
          '--spider',
          'http://localhost/health',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    profiles:
      - nginx

networks:
  prod-network:
    driver: bridge
    name: zaaz-prod-network

volumes:
  redis_data:
    driver: local
    name: zaaz-redis-prod-data
  rabbitmq_data:
    driver: local
    name: zaaz-rabbitmq-prod-data
  zookeeper_data:
    driver: local
    name: zaaz-zookeeper-prod-data
  kafka_data:
    driver: local
    name: zaaz-kafka-prod-data
